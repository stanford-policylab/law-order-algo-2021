{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Law, Order, and Algorithms\n", "## Algorithmic fairness (1/2)\n", "\n", "In 2016, ProPublica published a [now-famous article](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing) analyzing and criticizing the lack of fairness in a risk assessment tool used nationwide called COMPAS. Here, we will take a look at a cleaned-up version of the COMPAS data that ProPublica used, and try to better understand algorithmic fairness by investigating the claims ProPublica made, along with the [counterclaims](https://www.propublica.org/article/technical-response-to-northpointe) made by Northpointe (now re-branded as [Equivant](https://www.equivant.com/)).\n", "\n", "While Northpointe notes that their algorithm does not use race information and that their model is _calibrated_ across racial groups, ProPublica points out that the COMPAS scores differ in false positive rates across racial groups (violating classification parity). In this notebook, we will examine some of their claims by building and evaluating our own risk assessment tool."]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["# Some initial setup\n", "options(digits = 3)\n", "library(tidyverse)\n", "\n", "theme_set(theme_bw())\n", "\n", "# Because huge plots are ugly\n", "options(repr.plot.width = 6, repr.plot.height = 4)\n", "\n", "# Read the data\n", "compas_df <- read_rds(\"../data/compas.rds\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## COMPAS data"]}, {"cell_type": "markdown", "metadata": {}, "source": ["A cleaned version of the COMPAS data is loaded as `compas_df`, with the following columns\n", "\n", "* `id`: unique identifiers for each case\n", "* `sex`, `dob`, `age`, `race`: demographic information for each defendant\n", "* `recid_score`, `violence_score`: COMPAS scores assessing risk that a defendant will recidivate (`violence_score` for violent crimes) within two years of release (higher scores correspond to higher risk)\n", "* `priors_count`: number of prior arrests\n", "* `is_recid`, `is_violent_recid`: Indicator variable that is `1` if the defendant was arrested for a new (violent) crime within two years of release, and `0` otherwise"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["head(compas_df)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Exercise 1: Build a risk assessment model for recidivism\n", "\n", "We start by building our own risk assessment tool using only prior arrests (`priors_count`) and age (`age`) to predict whether a defendant will recidivate within two years of release (`is_recid`).\n", "First, fit a model to estimate the probability of this outcome for each defendant. \n", "We will call this model `recid_model`."]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["# Build a logistic regression model estimating recidivism probability\n", "\n", "recid_model <- \n", "# WRITE CODE HERE\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Given an estimate of risk (on the probability scale), we can compute a binary prediction of whether a defendant will recidivate or not by setting a decision threshold.\n", "Once a threshold is determined, defendants with estimated risk higher or equal to the threshold are predicted to recidivate.\n", "We can then compare the binary prediction to the observed outcome (`is_recid`) to compute the accuracy of our risk assessment tool at the specified threshold.\n", "We can similarly compute accuracy for COMPAS scores (`recid_score`) with some threshold.\n", "\n", "Calculate the accuracy for the `recid_model` that you fit above at a $50$% threshold, and for the COMPAS recidivism scores at a threshold of $4$ (which corresponds to approximately $50$%). To do so, first create a new column in the `compas_df` dataframe for estimated risk from your model above using the `predict()` function. Recall that you can generate model predictions with the command `predict(recid_model, type = \"response\")`, where `type = \"response\"` ensures predictions are in terms of probabilities, rather than log-odds. Then create a new binary column that indicates, for each person, whether their estimated risk is at least 50%. Similarly create a binary column that indicates whether their `recid_score` is at least 4. Finally, calculate accuracy (separately for the two binary predictors that you just created) by determining what proportion of the predictions align with the actual observed recidivism (`is_recid`)."]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["# WRITE CODE HERE\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Exercise 2: Calibration"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We next examine how well our model is calibrated across different race groups (i.e., for people who receive similar risk scores, we'll check whether the actual rate of recidivism is similar across race groups).\n", "\n", "To do so, we calculate two quantities:\n", "* `predicted_risk_score`: a discretized (rounded) version of our predicted risk from Exercise 1, similar to the COMPAS risk score;\n", "* `recidivism_rate`: the actual recidivism rate of people within a specific discretized risk score bucket.\n", "\n", "Calculate the above two quantities for both race groups in our dataset by creating a data frame called `calibration_by_race` containing three columns: `race`, `predicted_risk_score` (rounded to the nearest 10 percentage points), `recidivism_rate`.\n", "\n", "_Hint_: `round(x)` will round each element of `x` to the nearest integer."]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["# Calculate discretized risk score\n", "\n", "calibration_by_race <- compas_df %>%\n", "# WRITE CODE HERE\n", "\n", "# Put the recidivism rates of different race groups side by side\n", "calibration_by_race %>%\n", "    spread(race, recidivism_rate)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We can also visualize model calibration by plotting the risk score bins with their corresponding emprical recidivism rate:"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["# Calibration plot\n", "ggplot(calibration_by_race, \n", "       aes(x = predicted_risk_score, y = recidivism_rate, color = race)) +\n", "    geom_line() + geom_point() +\n", "    scale_y_continuous(labels = scales::percent_format(), limits = c(0, 1)) +\n", "    scale_x_continuous(labels = scales::percent_format(), limits = c(0, 1)) +\n", "    labs(x = \"\\nDiscretized risk score\",\n", "         y = \"Recidivism rate\\n\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The plot above suggets our model is well calibrated for Black and white defendants.\n", "In other words, Black and white defendants who receive similar risk scores have similar risk of recidivating."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Exercise 3: Cost-benefit analysis\n", "\n", "Detaining an individual incurs substantial social and financial costs, \n", "yet releasing a defendant can harm public safety.\n", "One strategy is to detain individuals with high recidivism risk while releasing those with low recidivism risk.\n", "In order to make such a detention policy based on our model, we need to decide on a detention threshold.\n", "\n", "To inform the detention decision, we'll attempt to estimate, for any given detention threshold,\n", "the proportion of crimes that would be prevented and at what cost.\n", "For the former, for a hypothetical detention policy, we'll estimate the proportion of defendants detained under that (hypothetical) policy who were in reality observed committing another crime. This measure, while imperfect, is a proxy for the the number of crimes prevented by detaining those individuals.\n", "For the latter, we'll compute the proportion of all defendants that are detained under the policy.\n", "\n", "This exercise is predicated on the assumption that it is acceptable to detain (at least some) individuals pretrial. \n", "Many, though, argue that (nearly) all defendants should be released on their own recognizance, in part because they have not yet been convicted of a crime. Further, even modest bail requirements can impose disproportionate burdens on the most vulnerable members of society. Some jurisdictions have taken steps toward reforming the pretrial processs \u2014 including [ending cash bail](https://www.npr.org/2021/02/22/970378490/illinois-becomes-first-state-to-eliminate-cash-bail) \u2014 though pretrial detention is still the norm rather than the exception.\n", "\n", "To examine hypothetical detention policies, complete the following function, which, given a data frame and a threshold, returns a new data frame including two columns: \n", "* `prop_crime_prevented`: the proportion of crime that is prevented under the policy (i.e., the estimated number of crimes prevented under the policy divided by the total number of observed crimes)\n", "* `prop_detained`: the proportion of the population that is detained under the policy\n", "\n", "We will assume that the data frame passed to the function contains at least the following columns:\n", "* `risk`: risk score that is used for the policy\n", "* `is_recid`: outcome indicating whether a defendant recidiviated"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["calc_cost_benefit <- function(d, threshold){\n", "    d %>%\n", "# WRITE CODE HERE\n", "}\n", "\n", "calc_cost_benefit(compas_df, threshold = 0.5)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Explore the cost-benefit characteristics of different policies that use different thresholds. "]}, {"cell_type": "markdown", "metadata": {}, "source": ["We can also plot this cost-benefit tradeoff for all possible detention thresholds using the following code:"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["cost_benefit_df <- map_dfr(unique(compas_df$risk), # for each unique value of risk\n", "                           ~ calc_cost_benefit(compas_df, .) %>% # calculate the costs and benefits\n", "                               mutate(threshold = .x)) # append the corresponding thresholds\n", "\n", "# Plot proportion detained vs. proportion crime prevented\n", "options(repr.plot.width = 4, repr.plot.height = 4)\n", "ggplot(cost_benefit_df, aes(x=prop_detained, y=prop_crime_prevented)) +\n", "    geom_line()+\n", "    scale_y_continuous(labels = scales::percent_format(), limits=c(0, 1))+\n", "    scale_x_continuous(labels = scales::percent_format(), limits=c(0, 1))+\n", "    labs(x = \"\\nProportion detained\",\n", "         y = \"Proportion crime prevented\\n\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Exercise 4: Disparities in detention"]}, {"cell_type": "markdown", "metadata": {}, "source": ["By conducting the above cost-benefit analysis,\n", "we can decide on a detention threshold, say 0.5, that we believe can maximize our benefit (crime prevention) at an acceptable cost of detaining some of the riskest defendants according to our model.\n", "\n", "Now, we would like to know whether such a facially neutral policy, where we detain everyone at the same threshold, will introduce disparities across defendants belonging to different race groups.\n", "\n", "To do so, let's compute the dentention rate for each race group using a detention threshold of 0.5."]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["# Calculate detention rate by race\n", "\n", "# WRITE CODE HERE\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Despite the same detention threshold being used, we still observe a difference in dentention rates.\n", "\n", "To further investigate, we can plot the distribution of risk for each of the two groups:"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["# Plot the risk distribution\n", "options(repr.plot.width = 7, repr.plot.height = 3.5)\n", "ggplot(compas_df, aes(x = risk, fill = race)) +\n", "    geom_density(alpha = 0.5, color = NA) +\n", "    scale_x_continuous(\"Estimated risk\", labels = scales::percent_format(), expand = c(0, 0)) +\n", "    scale_y_continuous(element_blank(), expand = c(0, 0)) +\n", "    theme(axis.ticks.y = element_blank(),\n", "          axis.text.y = element_blank())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Assuming that our model provides an accurate assessment of risk, we see that white and Black defendents have different risk distributions.\n", "\n", "Note: When considering disparate treatment, we are often concerned with what happens at the margin \n", "(e.g., whether the same standard is applied to all individuals).\n", "However, as we've seen in the past, popular summary statistics assess behavior away from the margin, hence they are called _infra-marginal_ statistics.\n", "This general phenomenon is known as the problem of infra-marginality ([Ayres, 2002](https://journals.sagepub.com/doi/abs/10.3818/JRP.4.1.2002.131); [Simoiu et al., 2017](https://5harad.com/papers/threshold-test.pdf); [Corbett-Davies and Goel, 2018](https://5harad.com/papers/fair-ml.pdf))."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Exercise 5: A \"fair\" policy by equalizing detention rates?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["After observing differences in the detention rates above, one natural thought might be to find a policy that equalizes detention rates across race groups.\n", "\n", "In this exercise, play around with different thresholds for Black and white defendants to achieve a detention rate of approximately 50% for each group."]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["black_threshold = 0.5\n", "white_threshold = 0.5\n", "\n", "# WRITE CODE HERE\n", "\n", "# Calculate detention rate by race\n", "compas_df %>%\n", "    mutate(detained = risk > if_else(race == \"Caucasian\", white_threshold, black_threshold)) %>%\n", "    group_by(race) %>%\n", "    summarize(\n", "        detention_rate = mean(detained),\n", "    )\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["What are the threshold values that you find? Which policy would you consider \"fair\", and why?"]}], "metadata": {"kernelspec": {"display_name": "R", "language": "R", "name": "ir"}, "language_info": {"codemirror_mode": "r", "file_extension": ".r", "mimetype": "text/x-r-source", "name": "R", "pygments_lexer": "r", "version": "3.6.3"}}, "nbformat": 4, "nbformat_minor": 4}