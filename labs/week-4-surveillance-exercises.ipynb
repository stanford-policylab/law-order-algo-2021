{"cells": [{"cell_type": "markdown", "id": "touched-investing", "metadata": {}, "source": ["# Law, Order, and Algorithms\n", "\n", "## Estimating San Francisco surveillance camera density"]}, {"cell_type": "code", "execution_count": 0, "id": "clinical-thong", "metadata": {}, "outputs": [], "source": ["# uncomment this line if have problems loading the libraries \n", "# install.packages(c(\"sf\", \"ggmap\"))\n", "library(tidyverse)\n", "library(sf)\n", "library(ggmap) # shouldn't need to add API key as I pre-saved the ggmap\n", "\n", "theme_set(theme_bw(base_size = 14))\n", "# suppress warnings\n", "options(warn = -1)"]}, {"cell_type": "markdown", "id": "married-beast", "metadata": {}, "source": ["In this lab, we are going to replicate results from the paper [Sheng et al. (2021)](https://5harad.com/papers/surveilling-surveillance.pdf) where they estimate the prevalence of surveillance cameras across the US using Google street view data.\n", "\n", "Specifically, we will perform two tasks in this lab:\n", "1) Estimate surveillance camera density in San Francisco;\n", "2) Examine whether the camera density is correlated with the share of minority population."]}, {"cell_type": "markdown", "id": "threaded-despite", "metadata": {}, "source": ["### Data"]}, {"cell_type": "code", "execution_count": 0, "id": "broke-rubber", "metadata": {}, "outputs": [], "source": ["# Load data\n", "load(file = \"../data/surveillance_sf.RData\")"]}, {"cell_type": "markdown", "id": "static-sunset", "metadata": {}, "source": ["We are loading three objects into the notebook, they are\n", "\n", "#### cameras_sf\n", "(row per image, only allow one detection per image)\n", "- `panoid`: ID of image \n", "- `lat-lon`: coordinates of image\n", "- `period`: year of image\n", "- `detected`, `verified`\n", "\n", "#### census_sf\n", "(row per census block group)\n", "- `GEOID`, `NAME`: ID and name of census block group\n", "- `total_pop`: total population of CBG\n", "- `total_white`: total non-Hispanic white population of CBG\n", "- `geometry`: multipolygon shape of census block group\n", "\n", "#### ggmap_sf\n", "- saved ggmap of San Francisco\n", "\n", "#### cameras_all\n", "(row per image, only allow one detection per image)\n", "- pre-cleaned file, variables should be self-explanatory"]}, {"cell_type": "markdown", "id": "wired-license", "metadata": {}, "source": ["### Object detection models"]}, {"cell_type": "markdown", "id": "fundamental-mobility", "metadata": {}, "source": ["In order to indentify cameras using street view images, we need to use a [object detection](https://en.wikipedia.org/wiki/Object_detection) model.\n", "An object detection model is a computer vision model that detects instances of objects of a certain class within an image.\n", "In this particular case we are interested in detecting cameras in an image, but in practice such model can be used to detec all kinds of objects.\n", "\n", "While object detection models' performance has increased drastically thanks to the rise of deep learning, enabling a number of previously impossible applications, they are not perfect models.\n", "In order to understand how well the camera detection model works, we evaluate it using two useful metrics: [precision and recall](https://en.wikipedia.org/wiki/Precision_and_recall).\n", "\n", "In our camera detection application, the existance of a camera is considered to be \"positive\".\n", "Given a dataset of camera detection prediction produced by our object detection model and the corresponding ground truth labels verified by humans, we can define the following terms:\n", "\n", "* P: the number of real positive cases in the data\n", "* N: the number of real negative cases in the data\n", "* TP: true positives; the number of predicted positive cases that were real positives \n", "* TN: true negatives; the number of predicted negative cases that were real negatives \n", "* FP: false positives; the number of predicted positives that were actually negative in the data (false alarms, Type I error)\n", "* FN: false negatives; the number of predicted negatives that were actually positive in the data (Type II error) \n", "\n", "Their definitions can be illustrated using following table:\n", "\n", "<br>\n", "<style type=\"text/css\">\n", ".tg  {border-collapse:collapse;border-spacing:0; margin: auto;}\n", ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#BBBBBB;}\n", ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#BBBBBB;}\n", ".tg .tg-baqh{text-align:center;vertical-align:top}\n", "</style>\n", "<table class=\"tg\">\n", "  <tr>\n", "    <th class=\"tg-baqh\"></th>\n", "    <th class=\"tg-baqh\">Real positive</th>\n", "    <th class=\"tg-baqh\">Real negative</th>\n", "  </tr>\n", "  <tr>\n", "    <td class=\"tg-baqh\">Predicted positive</td>\n", "    <td class=\"tg-baqh\">TP</td>\n", "    <td class=\"tg-baqh\">FP</td>\n", "  </tr>\n", "  <tr>\n", "    <td class=\"tg-baqh\">Predicted negative</td>\n", "    <td class=\"tg-baqh\">FN</td>\n", "    <td class=\"tg-baqh\">TN</td>\n", "  </tr>\n", "</table>\n", "<br>\n", "\n", "\n", "Precision is defined as\n", "$\\frac{TP}{TP + FP} = \\frac{N_{\\text{correctly identified cameras}}}{N_{\\text{identified cameras}}}$\n", "\n", "Recall is defined as\n", "$\\frac{TP}{TP + FN} = \\frac{N_{\\text{correctly identified cameras}}}{N_{\\text{real cameras}}}$\n", "\n", "\n", "This diagram from Wikipedia visually illustrates their definitions:\n", "\n", "![Precision and recall](../images/precision_recall.png)\n"]}, {"cell_type": "markdown", "id": "turkish-longitude", "metadata": {}, "source": ["#### Exercise: calculate model precision\n", "As an exercise, let's calculate the precision of our model using columns `verified` and `detected` from the data frame `cameras_sf`."]}, {"cell_type": "code", "execution_count": 0, "id": "certified-laser", "metadata": {}, "outputs": [], "source": ["# Your code here!\n"]}, {"cell_type": "markdown", "id": "unique-rehabilitation", "metadata": {}, "source": ["### Estimate surveillance camera detections and density in San Francisco\n", "\n", "As we see above, both the model's precision and recall are far from perfect.\n", "However, we are still able to use this model to help us estimate the number of cameras in SF.\n", "\n", "By running the camera detection model on a sample of street view images (in `cameras_sf`), we can estimate the total number of cameras in SF using three ingredients:\n", "1) The number of verified cameras in this sample\n", "2) Model recall\n", "3) Percentage of all roads in SF covered by the sample\n", "\n", "By running the camera detection model on a random sample of positive instances (i.e., images with cameras), we are able to obtain its recall of 0.67.\n", "Now let's calculate 1) and 3)."]}, {"cell_type": "markdown", "id": "headed-paraguay", "metadata": {}, "source": ["#### Exercise: calculate the number of verified cameras"]}, {"cell_type": "code", "execution_count": 0, "id": "random-passenger", "metadata": {}, "outputs": [], "source": ["# Calculate the number of verified cameras: n_verified\n", "# Your code here!\n", "n_verified"]}, {"cell_type": "markdown", "id": "colored-complex", "metadata": {}, "source": ["#### Exercise: calculate percentage of all roads in SF covered by the sample"]}, {"cell_type": "code", "execution_count": 0, "id": "thermal-venue", "metadata": {"tags": []}, "outputs": [], "source": ["# Constants\n", "# Total road length in San Francisco (meter)\n", "road_length_m <- 3108000\n", "# Average length of road covered by one image in the dataset meter\n", "avg_image_length_m <- 24.140665298930312\n", "\n", "# Calculate percentage of all roads in SF covered by the sample: perc_road_covered\n", "# Your code here!\n", "\n", "perc_road_covered"]}, {"cell_type": "markdown", "id": "dental-longer", "metadata": {}, "source": ["Now we are able to estimate the total number of cameras in SF.\n", "#### Exercise: derive the formula and calculate the estimated number of cameras in SF"]}, {"cell_type": "code", "execution_count": 0, "id": "phantom-henry", "metadata": {}, "outputs": [], "source": ["# Constants\n", "# Recall of the camera detection model\n", "recall <- 0.67\n", "\n", "# Estimate camera detections and density\n", "# Your code here!\n", "\n", "est_cameras"]}, {"cell_type": "markdown", "id": "durable-stranger", "metadata": {}, "source": ["And subsequently, we can calculate the camera density as follows:"]}, {"cell_type": "code", "execution_count": 0, "id": "stunning-welding", "metadata": {}, "outputs": [], "source": ["est_cameras_per_km <- est_cameras * 1000 / road_length_m\n", "est_cameras_per_km"]}, {"cell_type": "markdown", "id": "interested-plane", "metadata": {}, "source": ["### Plot camera detections on map\n", "We can plot the locations of detected cameras in our sample on map"]}, {"cell_type": "code", "execution_count": 0, "id": "nervous-despite", "metadata": {}, "outputs": [], "source": ["ggmap(ggmap_sf, extent = \"device\") +\n", "  geom_point(data = cameras_sf %>% \n", "               filter(verified),\n", "             aes(x = lon, y = lat),\n", "             position = \"jitter\", \n", "             shape = 25, fill = \"white\", color = \"red\",\n", "             alpha = 1, size = 1.5) +\n", "  theme(axis.text = element_blank(), \n", "        axis.title = element_blank(),\n", "        axis.ticks = element_blank(),\n", "        panel.grid = element_blank(),\n", "        panel.border = element_blank())"]}, {"cell_type": "markdown", "id": "obvious-operations", "metadata": {}, "source": ["### Plot detection rate against minority share for all cities\n", "By performing the analysis above for multiple cities across the US, we are able to plot the relationship between camera density and share of minorities in that location.\n", "\n", "[Discuss: what do we see here?]"]}, {"cell_type": "code", "execution_count": 0, "id": "partial-treatment", "metadata": {}, "outputs": [], "source": ["cameras_all %>%\n", "  ggplot(aes(x = percentage_minority, y = verified)) +\n", "  #geom_hline(yintercept = avg_detection_rate, linetype = \"dashed\", color = \"gray\") + # avg detection rate\n", "  geom_smooth(method = \"lm\", \n", "              formula = y ~ poly(x, degree = 2),\n", "              se = T) +\n", "  scale_x_continuous(\n", "    name = \"Minority share of population (census block group)\", \n", "    #breaks = seq(0, 1, 0.1),\n", "    expand = expansion(mult = c(0, 0.05)),\n", "    labels = scales::percent_format(accuracy = 1)\n", "  ) +\n", "  scale_y_continuous(\n", "    name = \"Identification rate\",  \n", "    breaks = seq(0, 0.012, 0.003),\n", "    expand = expansion(mult = c(0, 0.1)),\n", "    labels = scales::percent_format(accuracy = 0.1)\n", "  ) +\n", "  theme(\n", "    panel.grid = element_blank(),\n", "    panel.border = element_blank(),\n", "    axis.text = element_text(size = 24, family = \"Helvetica\", color = \"black\"),\n", "    axis.title = element_text(size = 24, family = \"Helvetica\", color = \"black\"),\n", "    axis.line = element_line(size = 0.5, color = \"black\"),\n", "    axis.ticks.x = element_line(size = 0.5, color = \"black\"),\n", "    axis.ticks.y = element_line(size = 0.5, color = \"black\")\n", "  ) "]}, {"cell_type": "markdown", "id": "played-contemporary", "metadata": {}, "source": ["## ===== everything below can be dropped =====\n", "### Plot detection rate against minority share (SF only)"]}, {"cell_type": "code", "execution_count": 0, "id": "ethical-reset", "metadata": {}, "outputs": [], "source": ["# NB: \n", "# - Plotting rates for each census block group instead of for each image.\n", "# - These plots don't look great due to the low number of points.\n", "df_sf <- st_join(\n", "    census_sf %>%\n", "      mutate(percentage_minority = (total_pop - total_white) / total_pop),\n", "    cameras_sf %>%\n", "      st_as_sf(coords = c(\"lon\", \"lat\"),\n", "               crs = 4269, # ensure same coords as tidycensus\n", "               agr = \"constant\")\n", "  ) %>%\n", "  group_by(GEOID) %>%\n", "  summarize(percentage_minority = first(percentage_minority),\n", "            detection_rate = sum(verified) / n()) %>% \n", "  suppressMessages()\n", "\n", "df_sf %>%\n", "  ggplot(aes(x = percentage_minority, y = detection_rate)) +\n", "  # Different modelling options: \n", "  #geom_point() +\n", "  geom_smooth(formula='y ~ x', method = 'loess') +\n", "  # geom_smooth(method = \"lm\",\n", "  #             formula = y ~ poly(x, degree = 2),\n", "  #             se = T) +\n", "  scale_x_continuous(\n", "    name = \"Minority share of population (census block group)\", \n", "    expand = expansion(mult = c(0, 0.05)),\n", "    labels = scales::percent_format(accuracy = 1)\n", "  ) +\n", "  scale_y_continuous(\n", "    name = \"Identification rate\",  \n", "    limits = c(0, NA),\n", "    oob = scales::squish,\n", "    expand = expansion(mult = c(0, 0.1)),\n", "    labels = scales::percent_format(accuracy = 0.1)\n", "  ) +\n", "  theme(\n", "    panel.grid = element_blank(),\n", "    panel.border = element_blank(),\n", "    axis.text = element_text(size = 24, family = \"Helvetica\", color = \"black\"),\n", "    axis.title = element_text(size = 24, family = \"Helvetica\", color = \"black\"),\n", "    axis.line = element_line(size = 0.5, color = \"black\"),\n", "    axis.ticks.x = element_line(size = 0.5, color = \"black\"),\n", "    axis.ticks.y = element_line(size = 0.5, color = \"black\")\n", "  ) "]}, {"cell_type": "markdown", "id": "accurate-forth", "metadata": {}, "source": ["### Plot camera detection rate as heatmap in SF"]}, {"cell_type": "code", "execution_count": 0, "id": "retained-tablet", "metadata": {}, "outputs": [], "source": ["ggplot(df_sf, aes(fill = detection_rate)) +\n", "  geom_sf() +\n", "  scale_x_continuous(limits = c(-122.52, -122.35)) +\n", "  scale_y_continuous(limits = c(37.7, 37.84)) +\n", "  scale_fill_viridis_c(\"Detection rate\", labels = scales::percent) +\n", "  theme(axis.text = element_blank(), \n", "        axis.title = element_blank(),\n", "        axis.ticks = element_blank(),\n", "        panel.grid = element_blank(),\n", "        panel.border = element_blank())"]}], "metadata": {"kernelspec": {"display_name": "R", "language": "R", "name": "ir"}, "language_info": {"codemirror_mode": "r", "file_extension": ".r", "mimetype": "text/x-r-source", "name": "R", "pygments_lexer": "r", "version": "4.0.5"}}, "nbformat": 4, "nbformat_minor": 5}