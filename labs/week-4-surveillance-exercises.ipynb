{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Law, Order, and Algorithms\n", "\n", "## Estimating the prevalence and placement of surveillance cameras"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["library(tidyverse)\n", "library(ggmap) \n", "# shouldn't need to add an API key as the relevant map is pre-saved\n", "\n", "theme_set(theme_bw(base_size = 14))\n", "options(digits = 3)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In this lab, we'll work to replicate the results from [Sheng et al. (2021)](https://5harad.com/papers/surveilling-surveillance.pdf), where the authors estimate the prevalence of surveillance cameras across the United States using Google street view data.\n", "\n", "Specifically, we will perform two tasks in this lab:\n", "1. Estimate the density of surveillance cameras in San Francisco;\n", "2. Examine the relationship between camera placement and the demographic composition of a neighborhood."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Data"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["# Load data\n", "load(file = \"../data/surveillance_sf.RData\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We are loading four objects into the notebook. They are:\n", "\n", "#### cameras_sf\n", "(one row per image)\n", "- `panoid`: ID of image \n", "- `lat-lon`: coordinates of image\n", "- `period`: year of image\n", "- `detected`, `verified`: whether a (verified) camera is in the image, explained below\n", "\n", "#### census_sf\n", "(one row per census block-group)\n", "- `GEOID`, `NAME`: ID and name of census block group (CBG)\n", "- `total_pop`: total population of CBG\n", "- `total_white`: total non-Hispanic white population of CBG\n", "- `geometry`: multipolygon shape of census block group\n", "\n", "#### cameras_all\n", "(one row per image, covering 10 U.S. cities)\n", "- `panoid`: ID of image \n", "- `city`: city of image\n", "- `period`: year of image\n", "- `verified`: indicator for whether the image contains a verified camera\n", "- `zone_type`: the designation of the area (e.g., `Residential` or `Commercial`) \n", "- `percentage_minority`: demographic composition of the CBG where the image was taken\n", "- census_block_group: the CBG of the image\n", "\n", "#### ggmap_sf\n", "- saved map of San Francisco"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["head(cameras_sf)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Object detection models"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In order to identify cameras using street view images, we will use an [object detection](https://en.wikipedia.org/wiki/Object_detection) model.\n", "An object detection model is a computer vision model that detects instances of objects of a certain class within an image.\n", "In this particular case we are interested in detecting cameras in an image, but in practice such models can be used to detect all kinds of objects.\n", "\n", "While object detection model performance has increased drastically due in large part to the rise of deep learning, enabling a number of previously impossible applications, they are not perfect models.\n", "In order to understand how well the camera detection model works, we evaluate it using two useful metrics: [precision and recall](https://en.wikipedia.org/wiki/Precision_and_recall).\n", "\n", "In our camera detection application, the existance of a camera is considered to be \"positive\".\n", "Given a dataset of camera detection predictions produced by our object detection model and the corresponding ground truth labels verified by humans, we can define the following terms:\n", "\n", "* P: the number of real positive cases in the data\n", "* N: the number of real negative cases in the data\n", "* TP: true positives; the number of predicted positive cases that were real positives \n", "* TN: true negatives; the number of predicted negative cases that were real negatives \n", "* FP: false positives; the number of predicted positives that were actually negative in the data (false alarms, Type I error)\n", "* FN: false negatives; the number of predicted negatives that were actually positive in the data (Type II error) \n", "\n", "Their definitions can be illustrated using following table:\n", "\n", "<br>\n", "<style type=\"text/css\">\n", ".tg  {border-collapse:collapse;border-spacing:0; margin: auto;}\n", ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#BBBBBB;}\n", ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#BBBBBB;}\n", ".tg .tg-baqh{text-align:center;vertical-align:top}\n", "</style>\n", "<table class=\"tg\">\n", "  <tr>\n", "    <th class=\"tg-baqh\"></th>\n", "    <th class=\"tg-baqh\">Real positive</th>\n", "    <th class=\"tg-baqh\">Real negative</th>\n", "  </tr>\n", "  <tr>\n", "    <td class=\"tg-baqh\">Predicted positive</td>\n", "    <td class=\"tg-baqh\">TP</td>\n", "    <td class=\"tg-baqh\">FP</td>\n", "  </tr>\n", "  <tr>\n", "    <td class=\"tg-baqh\">Predicted negative</td>\n", "    <td class=\"tg-baqh\">FN</td>\n", "    <td class=\"tg-baqh\">TN</td>\n", "  </tr>\n", "</table>\n", "<br>\n", "\n", "\n", "Precision is defined as\n", "$\\frac{TP}{TP + FP} = \\frac{N_{\\text{correctly identified cameras}}}{N_{\\text{identified cameras}}}$\n", "\n", "Recall is defined as\n", "$\\frac{TP}{TP + FN} = \\frac{N_{\\text{correctly identified cameras}}}{N_{\\text{real cameras}}}$\n", "\n", "\n", "This diagram from Wikipedia visually illustrates these definitions:\n", "\n", "![Precision and recall](../images/precision_recall.png)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Exercise: calculate model precision\n", "We previously trained a camera detection model, which we then applied to a sample of Google street view images. Afterwards, human annotators reviewed each of the images in which a camera was `detected` by the model and `verified` whether a camera was actually there.\n", "Now, as an exercise, let's calculate the precision of our model using the columns `verified` and `detected` from the data frame `cameras_sf`. "]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["# Your code here!\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Estimating the prevalence of surveillance cameras in San Francisco\n", "\n", "As we see above, the model's performance is far from perfect.\n", "However, we are still able to use this model to help us estimate the number of cameras in SF.\n", "\n", "By running the camera detection model on a random sample of street view images (in `cameras_sf`), we can estimate the total number of cameras in SF using three ingredients:\n", "\n", "1. The number of verified cameras in this sample\n", "1. The percentage of all roads in SF covered by the sample\n", "1. The model's recall\n", "\n", "By running the camera detection model on a random sample of positive instances (i.e., images with cameras), we estimate the model's recall is 0.67. (Discuss: why is this more laborious than calculating precision?)\n", "Now let's carry out steps 1 and 2."]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Exercise: calculate the number of verified cameras in our SF sample"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["# Calculate the number of verified cameras: n_verified\n", "# Your code here!\n", "n_verified"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Exercise: calculate the percentage of roadway in SF covered by the sample"]}, {"cell_type": "code", "execution_count": 0, "metadata": {"tags": []}, "outputs": [], "source": ["# Constants\n", "# Total road length in San Francisco (in meters)\n", "road_length_m <- 3108000\n", "# Average length of road covered by one image in the dataset (in meters)\n", "avg_image_length_m <- 24.1\n", "\n", "# Calculate percentage of all roads in SF covered by the sample: perc_road_covered\n", "# Your code here!\n", "\n", "perc_road_covered"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now we are able to estimate the total number of cameras in SF visible from the road.\n", "#### Exercise: derive a formula to estimate the number of cameras in SF"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["# Constants\n", "# Recall of the camera detection model\n", "recall <- 0.67\n", "\n", "# Estimate camera detections and density\n", "# Your code here!\n", "\n", "est_cameras"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Finally, we can calculate the camera density as follows:"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["est_cameras_per_km <- est_cameras / (road_length_m / 1000)\n", "est_cameras_per_km"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Plotting the location of camera detections\n", "We can plot the locations of detected cameras in our sample on a map to help us better understand their spatial distribution. What patterns do you notice in the placement of cameras?"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["ggmap(ggmap_sf, extent = \"device\") +\n", "  geom_point(data = cameras_sf %>% \n", "               filter(verified),\n", "             aes(x = lon, y = lat),\n", "             position = \"jitter\", \n", "             shape = 25, fill = \"white\", color = \"red\",\n", "             alpha = 1, size = 1.5) +\n", "  theme(axis.text = element_blank(), \n", "        axis.title = element_blank(),\n", "        axis.ticks = element_blank(),\n", "        panel.grid = element_blank(),\n", "        panel.border = element_blank())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Racial disparities in camera placement\n", "By performing the analysis above for multiple cities across the U.S. and combining the results with census data,\n", "we can examine the relationship between camera density and share of minorities (defined as those who identify as either Hispanic or non-white) in that location.\n", "\n", "Discuss: what do we see here? What might be driving the results?"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["cameras_all %>%\n", "  ggplot(aes(x = percentage_minority, y = verified)) +\n", "  #geom_hline(yintercept = avg_detection_rate, linetype = \"dashed\", color = \"gray\") + # avg detection rate\n", "  geom_smooth(method = \"lm\", \n", "              formula = y ~ poly(x, degree = 2),\n", "              se = T) +\n", "  scale_x_continuous(\n", "    name = \"Minority share of population (in CBG)\", \n", "    #breaks = seq(0, 1, 0.1),\n", "    expand = expansion(mult = c(0, 0.05)),\n", "    labels = scales::percent_format(accuracy = 1)\n", "  ) +\n", "  scale_y_continuous(\n", "    name = \"Camera identification rate\",  \n", "    breaks = seq(0, 0.012, 0.003),\n", "    expand = expansion(mult = c(0, 0.1)),\n", "    labels = scales::percent_format(accuracy = 0.1)\n", "  ) +\n", "  theme(\n", "    panel.grid = element_blank(),\n", "    panel.border = element_blank(),\n", "    axis.text = element_text(size = 24, family = \"Helvetica\", color = \"black\"),\n", "    axis.title = element_text(size = 24, family = \"Helvetica\", color = \"black\"),\n", "    axis.line = element_line(size = 0.5, color = \"black\"),\n", "    axis.ticks.x = element_line(size = 0.5, color = \"black\"),\n", "    axis.ticks.y = element_line(size = 0.5, color = \"black\")\n", "  ) "]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "R", "language": "R", "name": "ir"}, "language_info": {"codemirror_mode": "r", "file_extension": ".r", "mimetype": "text/x-r-source", "name": "R", "pygments_lexer": "r", "version": "3.6.3"}}, "nbformat": 4, "nbformat_minor": 5}