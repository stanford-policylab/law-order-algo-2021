{"nbformat_minor": 2, "metadata": {"kernelspec": {"language": "R", "display_name": "R", "name": "ir"}, "language_info": {"codemirror_mode": "r", "mimetype": "text/x-r-source", "pygments_lexer": "r", "version": "3.4.4", "file_extension": ".r", "name": "R"}}, "nbformat": 4, "cells": [{"metadata": {}, "source": ["# Law, Bias, and Algorithms\n", "## Algorithmic fairness (1/2)\n", "\n", "In 2016, ProPublica published a [now-famous article](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing) analyzing and criticizing the lack of fairness in a risk assessment tool used nationwide called COMPAS. Here, we will take a look at a cleaned-up version of the COMPAS data that ProPublica used, and try to better understand algorithmic fairness by investigating the claims ProPublica made, along with the [counterclaims](https://www.propublica.org/article/technical-response-to-northpointe) made by Northpointe (now re-branded as [Equivant](https://www.equivant.com/)).\n", "\n", "While Northpointe notes that their algorithm does not use race information and that their model is calibrated across racial groups, ProPublica points out that the COMPAS scores differ in false positive rates across racial groups (violating classification parity). In this notebook, we will examine some of their claims by building and evaluating our own risk assessment tool."], "cell_type": "markdown"}, {"metadata": {}, "execution_count": 0, "source": ["# Some initial setup\n", "options(digits = 3)\n", "library(tidyverse)\n", "\n", "theme_set(theme_bw())\n", "\n", "# Because huge plots are ugly\n", "options(repr.plot.width = 6, repr.plot.height = 4)\n", "\n", "# Read the data\n", "compas_df <- read_rds(\"../data/compas.rds\")"], "cell_type": "code", "outputs": []}, {"metadata": {}, "source": ["## COMPAS data"], "cell_type": "markdown"}, {"metadata": {}, "source": ["A cleaned version of the COMPAS data is loaded as `compas_df`, with the following columns\n", "\n", "* `id`: unique identifiers for each case\n", "* `sex`, `dob`, `age`, `race`: demographic information for each defendant\n", "* `recid_score`, `violence_score`: COMPAS scores assessing risk that a defendant will recidivate (`violence_score` for violent crimes) within two years of release (higher scores correspond to higher risk)\n", "* `priors_count`: number of prior arrests\n", "* `is_recid`, `is_violent_recid`: Indicator variable that is `1` if the defendant was arrested for a new (violent) crime within two years of release, and `0` otherwise."], "cell_type": "markdown"}, {"metadata": {}, "execution_count": 0, "source": ["head(compas_df)"], "cell_type": "code", "outputs": []}, {"metadata": {}, "source": ["### Exercise 1: Build a risk assessment model for recidivism\n", "\n", "We start by building our own risk assessment tool using only prior arrests (`priors_count`) and age (`age`) to predict whether a defendant will recidivate within two years of release (`is_recid`).\n", "First, fit a model to estimate the probability of this outcome for each defendant. \n", "We will call this model `recid_model`."], "cell_type": "markdown"}, {"metadata": {}, "execution_count": 0, "source": ["# Build a logistic regression model estimating recidivism probability\n", "\n", "recid_model <- \n", "# WRITE CODE HERE\n"], "cell_type": "code", "outputs": []}, {"metadata": {}, "source": ["Given an estimate of risk (on the probability scale), we can compute a binary prediction of whether a defendant will recidivate or not by setting a decision threshold.\n", "Once a threshold is determined, defendants with estimated risk higher or equal to the threshold are predicted to recidivate.\n", "We can then compare the binary prediction to the observed outcome (`is_recid`) to compute the accuracy of our risk assessment tool at the specified threshold.\n", "We can similarly compute accuracy for COMPAS scores (`recid_score`) with some threshold.\n", "\n", "Calculate the accuracy for the `recid_model` that you fit above at a $50$% threshold, and for the COMPAS recidivism scores at a threshold of $4$ (which corresponds to approximately $50$%)."], "cell_type": "markdown"}, {"metadata": {}, "execution_count": 0, "source": ["# WRITE CODE HERE\n"], "cell_type": "code", "outputs": []}, {"metadata": {}, "source": ["### Exercise 2: Calibration"], "cell_type": "markdown"}, {"metadata": {}, "source": ["We next examine how well our model is calibrated across different race groups (i.e., for people who receive similar risk scores, what is the actual rate of recidivism across each race group).\n", "\n", "To do so, we calculate two quantities:\n", "* `predicted_risk_score`: a discretized (rounded) version of our predicted risk from Exercise 1, similar to the COMPAS risk score;\n", "* `recidivism_rate`: the actual recidivism rate of people within a specific discretized risk score bucket.\n", "\n", "Calculate the above two quantities for both race groups in our dataset by creating a data frame called `calibration_by_race` containing three columns: `race`, `predicted_risk_score` (rounded to the nearest 10 percentage points), `recidivism_rate`.\n", "\n", "_Hint_: `round(x)` will round each element of `x` to the nearest integer."], "cell_type": "markdown"}, {"metadata": {}, "execution_count": 0, "source": ["# Calculate discretized risk score\n", "\n", "calibration_by_race <- compas_df %>%\n", "# WRITE CODE HERE\n", "\n", "# Put the recidivism rates of different races side by side\n", "calibration_by_race %>%\n", "    spread(race, recidivism_rate)"], "cell_type": "code", "outputs": []}, {"metadata": {}, "source": ["We can also visualize model calibration by plotting the risk score bins with their corresponding emprical recidivism rate:"], "cell_type": "markdown"}, {"metadata": {}, "execution_count": 0, "source": ["# Calibration plot\n", "ggplot(calibration_by_race, \n", "       aes(x = predicted_risk_score, y = recidivism_rate, color = race)) +\n", "    geom_line() + \n", "    scale_y_continuous(labels = scales::percent_format(), limits = c(0, 1))+\n", "    scale_x_continuous(breaks = seq(0, 10, 2), limits = c(1, 10))+\n", "    labs(x = \"\\nDiscretized risk score\",\n", "         y = \"Recidivism rate\\n\")"], "cell_type": "code", "outputs": []}, {"metadata": {}, "source": ["The plot above suggets our model is well calibrated for black and white defendants.\n", "In other words, black and white defendants who receive similar risk scores have similar risk of recidivating."], "cell_type": "markdown"}, {"metadata": {}, "source": ["### Exercise 3: Cost-benefit analysis\n", "\n", "Detaining an individual incurs substantial financial and social costs, \n", "yet releasing a defendant can harm public safety.\n", "One strategy is to detain individuals with high recidivism risk while releasing those with low recidivism risk.\n", "In order to make such a detention policy based on our model, we need to decide on a detention threshold.\n", "\n", "To inform that decision, we'll attempt to estimate, for any given detention threshold,\n", "the proportion of crimes that would be prevented and at what cost.\n", "For the former, we'll compute the proportion of defendants who ultimately commit another crime that are detained under the policy; for the latter, we'll compute the proportion of all defendants that are detained.\n", "\n", "For this exercise, complete the following function which, given a data frame and a threshold, returns a new data frame including two columns: \n", "* `prop_crime_prevented`: the proportion of crime that is prevented, and\n", "* `prop_detained`: the proportion of the population that is detained\n", "\n", "We will assume that the data frame passed to the function contains at least the following columns:\n", "* `risk`: risk score that is used for the policy\n", "* `is_recid`: outcome indicating whether a defendant recidiviated"], "cell_type": "markdown"}, {"metadata": {}, "execution_count": 0, "source": ["calc_cost_benefit <- function(d, threshold){\n", "    d %>%\n", "# WRITE CODE HERE\n", "}\n", "\n", "calc_cost_benefit(compas_df, threshold = 0.5)"], "cell_type": "code", "outputs": []}, {"metadata": {}, "source": ["Explore the cost-benefit characteristics of different policies that use different thresholds. "], "cell_type": "markdown"}, {"metadata": {}, "source": ["We can also plot this cost-benefit tradeoff for all possible detention thresholds using the following code:"], "cell_type": "markdown"}, {"metadata": {}, "execution_count": 0, "source": ["cost_benefit_df <- map_dfr(unique(compas_df$risk), \n", "                           ~ calc_cost_benefit(compas_df, .) %>%\n", "                               mutate(threshold = .x))\n", "\n", "# Plot proportion detained vs. proportion crime prevented\n", "options(repr.plot.width = 4, repr.plot.height = 4)\n", "ggplot(cost_benefit_df, aes(x=prop_detained, y=prop_crime_prevented)) +\n", "    geom_line()+\n", "    scale_y_continuous(labels = scales::percent_format(), limits=c(0, 1))+\n", "    scale_x_continuous(labels = scales::percent_format(), limits=c(0, 1))+\n", "    labs(x = \"\\nProportion detained\",\n", "         y = \"Proportion crime prevented\\n\")"], "cell_type": "code", "outputs": []}, {"metadata": {}, "source": ["### Exercise 4: Disparities in detention"], "cell_type": "markdown"}, {"metadata": {}, "source": ["By conducting the above cost-benefit analysis,\n", "we can decide on a detention threshold, say $0.5$, that we believe can maximize our benefit (crime prevention) at a acceptable cost of detaining some of the riskest defendants according to our model.\n", "\n", "Now, we would like to know whether such a facially neutral policy, where we detain everyone at the same threshold, will introduce disparities across defendants of different races.\n", "\n", "To do so, let's compute the dentention rate for each race group using a detention threshold of 0.5."], "cell_type": "markdown"}, {"metadata": {}, "execution_count": 0, "source": ["# Calculate detention and recidivism rate by race\n", "\n", "# WRITE CODE HERE\n"], "cell_type": "code", "outputs": []}, {"metadata": {}, "source": ["Despite the same detention threshold being used, we still observe a difference in dentention rates.\n", "\n", "To further investigate, we can plot the distribution of risk for each of the two groups:"], "cell_type": "markdown"}, {"metadata": {}, "execution_count": 0, "source": ["# Plot the risk distribution\n", "options(repr.plot.width = 7, repr.plot.height = 3.5)\n", "ggplot(compas_df, aes(x = risk, fill = race)) +\n", "    geom_density(alpha = 0.5, color = NA) +\n", "    scale_x_continuous(\"Estimated risk\", labels = scales::percent_format(), expand = c(0, 0)) +\n", "    scale_y_continuous(element_blank(), expand = c(0, 0)) +\n", "    theme(axis.ticks.y = element_blank(),\n", "          axis.text.y = element_blank())"], "cell_type": "code", "outputs": []}, {"metadata": {}, "source": ["Assuming that our model provides an accurate assessment of risk, we see that white and black defendents have different risk distributions.\n", "When we are making a policy decision, we are often concerned with what happens at the margin \n", "(e.g., whether the same standard is applied to all individuals).\n", "However, popular error metrics assess behavior away from the margin, hence they are called infra-marginal statistics.\n", "This general phenomenon is known as the problem of _infra-marginality_ (Ayres, 2002; Simoiu et al., 2017; Corbett-Davies and Goel, 2018)."], "cell_type": "markdown"}, {"metadata": {}, "source": ["### Exercise 5: A \"fair\" policy by equalizing detention rates?"], "cell_type": "markdown"}, {"metadata": {}, "source": ["After observing differences in the detention rates above, one natural thought might be to find a policy which equalizes detention rates across race groups.\n", "\n", "In this exercise, play around with different thresholds for black and white defendants to achieve a detention rate of approximately 50% for each group."], "cell_type": "markdown"}, {"metadata": {}, "execution_count": 0, "source": ["black_threshold = 0.5\n", "white_threshold = 0.5\n", "\n", "# WRITE CODE HERE\n", "\n", "# Calculate detention and recidivism rate by race\n", "compas_df %>%\n", "    mutate(detained = risk > if_else(race == \"Caucasian\", white_threshold, black_threshold)) %>%\n", "    group_by(race) %>%\n", "    summarize(\n", "        detention_rate = mean(detained),\n", "    )\n"], "cell_type": "code", "outputs": []}, {"metadata": {}, "source": ["What are the threshold values that you find? Which policy would you consider \"fair\", and why?"], "cell_type": "markdown"}]}